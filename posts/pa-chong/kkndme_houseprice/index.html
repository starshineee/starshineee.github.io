<!doctype html>
<html lang="chinese (simplified)">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>天涯 kkndme 大神论房价 | Starshineee 的个人博客
</title>
  <link rel="canonical" href="https://starshineee.github.io/posts/pa-chong/kkndme_houseprice/index.html">


  <link rel="stylesheet" href="https://starshineee.github.io/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://starshineee.github.io/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://starshineee.github.io/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="https://starshineee.github.io/theme/css/theme.css">


<meta name="description" content="天涯神贴不解释，由本人利用 python 爬虫爬得并整理。本文提供整理后文档的下载，并对爬虫进行了简述。">
  <script>
    (function(i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function() {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o);
      a.async = 1;
      a.src = g;
      m = s.getElementsByTagName(o)[0];
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-124959139-1', 'auto');
    ga('send', 'pageview');
  </script>


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="https://starshineee.github.io/">Starshineee 的个人博客</a></h1>
      <ul class="list-inline">
          <li class="list-inline-item"><a href="https://github.com/starshineee" target="_blank">我的Github</a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>天涯 kkndme 大神论房价
</h1>
      <hr>
<article class="article">
  <header>
    <ul class="list-inline">
      <li class="list-inline-item text-muted" title="2018-07-03T19:20:00+08:00">
        <i class="fa fa-clock-o"></i>
        周二 03 七月 2018
      </li>
      <li class="list-inline-item">
        <i class="fa fa-folder-open-o"></i>
        <a href="https://starshineee.github.io/category/pa-chong.html">爬虫</a>
      </li>
      <li class="list-inline-item">
        <i class="fa fa-user-o"></i>
        <a href="https://starshineee.github.io/author/starshineee.html">starshineee</a>      </li>
      <li class="list-inline-item">
        <i class="fa fa-files-o"></i>
        <a href="https://starshineee.github.io/tag/pa-chong.html">#爬虫</a>,         <a href="https://starshineee.github.io/tag/fang-shi.html">#房市</a>      </li>
    </ul>
  </header>
  <div class="content">
    <h1>文档简介及下载链接</h1>
<p>2010年天涯神贴，主要内容为 kkndme 大神对于房价、经济、历史等热点的看法。由于其准确预言了中国的经济和房价的发展历程，使得其在 2018 年被突然发现并迅速变为热帖。由于很多观点有着一定的敏感性，所以多处面临着删帖的风险。本人利用 python 爬虫将其整理成了一个文档并提供下载，以方便自己和大家阅读。遗憾的是本人下手太晚，一些楼层已经被删贴了，但剩下的那部分依然能够反映出 kkndme 大神的观点，读之如饮醇醪。</p>
<p>下载链接：
<!-- <a href="https://starshineee.github.io/pdfs/天涯kkndme神贴论房价.pdf">pdf 版 kkndme 论房价</a> -->
<a href="https://starshineee.github.io/pdfs/天涯kkndme神贴论房价.pdf" download>pdf 版 kkndme 论房价</a></p>
<h1>爬虫思路</h1>
<p>爬虫的本质是利用计算机来模拟人访问页面的行为，所以我们首先要想我们自己访问天涯神贴的时候怎么操作的。事实上，我们有两种途径：一种是访问<a href="http://bbs.tianya.cn/post-5137-9507-1.shtml">PC版的界面</a>，一种是访问<a href="http://bbs.tianya.cn/m/post-house-252774-1.shtml">移动端的界面</a>。这两者中移动端的界面较为清爽，且可以通过点击“只看楼主”来滤掉大部分的非目标信息，对应的链接就变成了<a href="http://bbs.tianya.cn/m/post_author-house-252774-1.shtml">移动端只看楼主</a>，这样便大大地方便了我们的爬取。本文中代码默认需要使用者有库 requests, bs4, python-docx, time。</p>
<p>首先我们选择一个header并以此来对上述链接进行访问</p>
<div class="highlight"><pre><span></span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;http://bbs.tianya.cn/m/post_author-house-252774-1.shtml&#39;</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span><span class="s1">&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#39;</span>
    <span class="p">}</span>
<span class="n">r</span><span class="o">=</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="o">+</span><span class="n">page</span><span class="p">,</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="n">soup</span><span class="o">=</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
</pre></div>


<p>打印soup，我们可以看到其中已经包含了我们想要得到的网页中的一切信息，现在需要把我们感兴趣的信息提取出来，即kkndme大神的发帖内容，以及去往下一页的链接。</p>
<p>观察页面内容，发现我们感兴趣的帖子内容都在 "class=bd" 的 "div" 元素中，且都在首层的 "p" 元素中，因此可以通过下面代码得到每一段的内容。</p>
<div class="highlight"><pre><span></span><span class="n">contents</span><span class="o">=</span><span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span><span class="n">class_</span><span class="o">=</span><span class="s1">&#39;bd&#39;</span><span class="p">)</span>
<span class="n">paragraphs</span><span class="o">=</span><span class="n">content</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s2">&quot;p&quot;</span><span class="p">,</span><span class="n">recursive</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">paragraphs</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>
</pre></div>


<p>在 "class=u-btn next-btn" 的 "a" 元素中我们能找到向下一页跳转的链接，这样我们就可以自动地去访问下一个页面。</p>
<div class="highlight"><pre><span></span><span class="n">next_page</span><span class="o">=</span><span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="n">class_</span><span class="o">=</span><span class="s1">&#39;u-btn next-btn&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
</pre></div>


<p>看起来好像我们已经得到了我们想要的，然而访问几个页面后就会出现问题。。。这是因为天涯允许匿名访客访问限制数目的页面，但再往后就要登录才能访问。这个时候我们就需要先用自己的账号登录，如下图所示在 chrome 中利用 F12 查看自己的 cookie，处理后填到 requests 中。</p>
<!-- ![获取cookie]({filename}/images/获取cookie.png){: width="600px" height="400px"} -->

<p><img alt="获取cookie" height="50%" src="https://starshineee.github.io/images/获取cookie.png" width="60%"></p>
<p>最后利用 python-docx 包将帖子内容存进 word 文档中，本文中所提供的 pdf 即由该 word 转化而来。</p>
<h1>最终代码</h1>
<p>假如你看到了这里，那说明你对于技术有一定的兴趣。爬取页面的大致思路如上文所述，具体的代码要复杂一些，可以到我的<a href="https://github.com/starshineee/tianya-kkndme-crawl">github页面</a>上去下载。</p>
<p>本博客不定期更新，主要内容为爬虫、大数据、各种小工具等技术问题，欢迎到 github 上 follow 我。</p>
  </div>


  <script data-isso="http://52.195.11.64/isso/"
        data-isso-css="true"
        data-isso-lang="zh_CN"
        data-isso-reply-to-self="true"
        data-isso-require-author="false"
        data-isso-require-email="false"
        data-isso-max-comments-top="10"
        data-isso-max-comments-nested="5"
        data-isso-reveal-on-click="5"
        data-isso-avatar="true"
        data-isso-avatar-bg="#f0f0f0"
        data-isso-avatar-fg="#9abf88 #5698c4 #e279a3 #9163b6 ..."
        data-isso-vote="true"
        data-vote-levels=""
        src="http://52.195.11.64:8090/js/embed.js"></script>
  <section id="isso-thread"></section>


</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
      <li class="list-inline-item"><a href="https://starshineee.github.io/authors.html">Authors</a></li>
    <li class="list-inline-item"><a href="https://starshineee.github.io/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="https://starshineee.github.io/categories.html">Categories</a></li>
      <li class="list-inline-item"><a href="https://starshineee.github.io/tags.html">Tags</a></li>
  </ul>
  <!-- <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p> -->
</div>    </div>
  </footer>
</body>

</html>